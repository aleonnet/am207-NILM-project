\BOOKMARK [1][-]{section.1}{1 Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{1.1 Data processing}{section.1}% 2
\BOOKMARK [1][-]{section.2}{2 Methods}{}% 3
\BOOKMARK [2][-]{subsection.2.1}{2.1 Combinatorial Optimization}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.2}{2.2 Factorial Hidden Markov Model}{section.2}% 5
\BOOKMARK [1][-]{section.3}{3 Convolutional Neural Network \(ConvNet\)}{}% 6
\BOOKMARK [2][-]{subsection.3.1}{3.1 ConvNet introduction}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.2}{3.2 Data pipeline}{section.3}% 8
\BOOKMARK [3][-]{subsubsection.3.2.1}{3.2.a Dealing with unbalanced data: selecting aggregated and synthetic data windows}{subsection.3.2}% 9
\BOOKMARK [3][-]{subsubsection.3.2.2}{3.2.b Standardization of the input data}{subsection.3.2}% 10
\BOOKMARK [3][-]{subsubsection.3.2.3}{3.2.c Output data \(start time, end time and average power\)}{subsection.3.2}% 11
\BOOKMARK [2][-]{subsection.3.3}{3.3 Implementation strategy for real time data augmentation}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.4}{3.4 ConvNet architecture}{section.3}% 13
\BOOKMARK [2][-]{subsection.3.5}{3.5 Loss function and optimizer}{section.3}% 14
\BOOKMARK [3][-]{subsubsection.3.5.1}{3.5.a Loss function}{subsection.3.5}% 15
\BOOKMARK [2][-]{subsection.3.6}{3.6 Optimizer}{section.3}% 16
\BOOKMARK [2][-]{subsection.3.7}{3.7 Training and Validation losses}{section.3}% 17
\BOOKMARK [1][-]{section.4}{4 Results and Discussion}{}% 18
\BOOKMARK [1][-]{section.5}{5 Conclusion}{}% 19
